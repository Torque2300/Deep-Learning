{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\3741198026.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\3741198026.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n"
     ]
    }
   ],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.006760443547122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\1098455523.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\2688850719.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\2688850719.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\2688850719.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\2688850719.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\3211748656.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\3211748656.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
      "C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\ipykernel_24408\\3211748656.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  target_index = np.ones(batch_size, dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fda025efa0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.127\n",
      "Accuracy after training for 100 epochs:  0.121\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "# TODO use validation set to find the best hyperparameters\n",
    "# hint: for best results, you might need to try more values for learning rate and regularization strength \n",
    "# than provided initially\n",
    "\n",
    "for rate in learning_rates:\n",
    "    for strength in reg_strengths:\n",
    "        classifier.fit(train_X, train_y, epochs=num_epochs, learning_rate=rate, batch_size=batch_size, reg=strength)\n",
    "        prediction = classifier.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(prediction, val_y)\n",
    "        if best_val_accuracy < accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            best_classifier = classifier\n",
    "\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
